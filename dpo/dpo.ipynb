{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabbbe0a-918c-4381-995c-793fe5fa989f",
   "metadata": {},
   "source": [
    "Task 1: Building positive-negative data pairs.\n",
    "\n",
    "Since the pretrained NanoGPT only knows QA-type responses, we need to create a dataset that contrasts incorrect model-style answers with correct, human-preferred answers to math problems. \n",
    "These pairs will later be used for DPO fine-tuning\n",
    "\n",
    "Approach:\n",
    "1. Load existing QA pairs (if avail.)\n",
    "2. Generate additional arithmeetic & algebra problems automatically\n",
    "3. For each problem, create:\n",
    "   - a negative response\n",
    "   - a positive response (human-correct, with explanation)\n",
    "4. Save all to the provided .json file.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d9ba2a-feda-4072-9d2b-694283ebf5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, math, os, pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa08634-e498-4737-8893-d2b4a024d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46afff5-bc5e-4173-9dce-d31ea4501257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "save_path = \"C:/Users/syedr/OneDrive/Documents/NTU Semester Resources/NTU Y3S1/SC3000 - Artificial Intelligence/Lab 1/NanoGPT-Math-main/dpo/pos_neg_pairs.json\"\n",
    "os.makedirs(\"dpo\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fc5d27-79cf-411a-91e6-f2617672f35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40000 existing samples from C:/Users/syedr/OneDrive/Documents/NTU Semester Resources/NTU Y3S1/SC3000 - Artificial Intelligence/Lab 1/NanoGPT-Math-main/dpo/pos_neg_pairs.json\n"
     ]
    }
   ],
   "source": [
    "# Load existing base data if present\n",
    "base = []\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        base = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(base)} existing samples from {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f5c8e4-3dbd-4515-85fd-5d0bc306aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to create problems\n",
    "def make_add(a, b):\n",
    "    q = f\"{a}+{b}=?\"\n",
    "    ans = a + b\n",
    "    pos = f\"{q} The answer is {ans} because {a}+{b} equals {ans}.\"\n",
    "    neg = f\"{q} Hmm, I’m not sure!\"\n",
    "    return {\"negative\": neg, \"positive\": pos}\n",
    "\n",
    "def make_sub(a, b):\n",
    "    q = f\"{a}-{b}=?\"\n",
    "    ans = a - b\n",
    "    pos = f\"{q} The answer is {ans} because {a}-{b} equals {ans}.\"\n",
    "    neg = f\"{q} Sorry, I don’t know the answer!\"\n",
    "    return {\"negative\": neg, \"positive\": pos}\n",
    "\n",
    "def make_mul(a, b):\n",
    "    q = f\"{a}*{b}=?\"\n",
    "    ans = a * b\n",
    "    pos = f\"{q} The answer is {ans} because {a}×{b} equals {ans}.\"\n",
    "    neg = f\"{q} Sorry, I don’t know!\"\n",
    "    return {\"negative\": neg, \"positive\": pos}\n",
    "\n",
    "def make_div(a, b):\n",
    "    if b == 0:\n",
    "        b = 1\n",
    "    a = a - (a % b)\n",
    "    q = f\"{a}/{b}=?\"\n",
    "    ans = a // b\n",
    "    pos = f\"{q} The answer is {ans} because {a}/{b} equals {ans}.\"\n",
    "    neg = f\"{q} I think it’s {random.randint(0,9)}, but not sure.\"\n",
    "    return {\"negative\": neg, \"positive\": pos}\n",
    "\n",
    "def make_linear(a, b):\n",
    "    # ax + b = c  -> x = (c - b)/a\n",
    "    if a == 0:\n",
    "        a = 1\n",
    "    x = random.randint(-20, 50)\n",
    "    c = a * x + b\n",
    "    q = f\"{a}*x+{b}={c}, x=?\"\n",
    "    ans = x\n",
    "    pos = f\"{q} The answer is {ans} because ({c}-{b})/{a} = {ans}.\"\n",
    "    neg = f\"{q} Sorry, I’m not sure how to solve that.\"\n",
    "    return {\"negative\": neg, \"positive\": pos}\n",
    "\n",
    "def make_two_step():\n",
    "    # Example: (x + a)*b = c\n",
    "    a = random.randint(1, 10)\n",
    "    b = random.randint(1, 10)\n",
    "    x = random.randint(0, 20)\n",
    "    c = (x + a) * b\n",
    "    q = f\"(x+{a})*{b}={c}, x=?\"\n",
    "    pos = f\"{q} The answer is {x} because x+{a}={c}/{b}={c//b}, so x={x}.\"\n",
    "    neg = f\"{q} Hmm… maybe {random.randint(0,10)}?\"\n",
    "    return {\"negative\": neg, \"positive\": pos}\n",
    "\n",
    "def make_word():\n",
    "    # Word-style simple arithmetic\n",
    "    a = random.randint(1, 10)\n",
    "    b = random.randint(1, 10)\n",
    "    ans = a + b\n",
    "    q = f\"Tom has {a} apples and buys {b} more. How many apples does he have in total?\"\n",
    "    pos = f\"{q} He has {ans} apples because {a}+{b}={ans}.\"\n",
    "    neg = f\"{q} Sorry, I don’t know!\"\n",
    "    return {\"negative\": neg, \"positive\": pos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602ee926-e80d-439f-a7a4-7a95264e7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "target_total = 40000\n",
    "need = max(0, target_total - len(base))\n",
    "\n",
    "pairs = []\n",
    "ops = [\"add\", \"sub\", \"mul\", \"div\", \"linear\", \"two_step\", \"word\"]\n",
    "weights = [0.2, 0.15, 0.2, 0.1, 0.2, 0.1, 0.05]\n",
    "\n",
    "for _ in range(need):\n",
    "    op = random.choices(ops, weights=weights)[0]\n",
    "    if op == \"add\":\n",
    "        pairs.append(make_add(random.randint(0, 999), random.randint(0, 999)))\n",
    "    elif op == \"sub\":\n",
    "        pairs.append(make_sub(random.randint(0, 999), random.randint(0, 999)))\n",
    "    elif op == \"mul\":\n",
    "        pairs.append(make_mul(random.randint(0, 99), random.randint(0, 20)))\n",
    "    elif op == \"div\":\n",
    "        pairs.append(make_div(random.randint(1, 999), random.randint(1, 20)))\n",
    "    elif op == \"linear\":\n",
    "        pairs.append(make_linear(random.randint(-9, 9) or 1, random.randint(-50, 100)))\n",
    "    elif op == \"two_step\":\n",
    "        pairs.append(make_two_step())\n",
    "    elif op == \"word\":\n",
    "        pairs.append(make_word())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8a9ae8-e8d2-4ae9-a642-2b406513f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with existing, shuffle\n",
    "combined = base + pairs\n",
    "random.shuffle(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601e572d-8041-4039-916f-d402ca9a47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved expanded dataset with 40000 examples to C:/Users/syedr/OneDrive/Documents/NTU Semester Resources/NTU Y3S1/SC3000 - Artificial Intelligence/Lab 1/NanoGPT-Math-main/dpo/pos_neg_pairs.json\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved expanded dataset with {len(combined)} examples to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921dcff9-1dea-4bd0-a82b-fe80f1d5fc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984/3=? I think it’s 0, but not sure.</td>\n",
       "      <td>984/3=? The answer is 328 because 984/3 equals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2*6=? Sorry, I don’t know!</td>\n",
       "      <td>2*6=? The answer is 12 because 2×6 equals 12.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210+36=? Hmm, I’m not sure!</td>\n",
       "      <td>210+36=? The answer is 246 because 210+36 equa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4*x+75=203, x=? Sorry, I’m not sure how to sol...</td>\n",
       "      <td>4*x+75=203, x=? The answer is 32 because (203-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867+516=? Hmm, I’m not sure!</td>\n",
       "      <td>867+516=? The answer is 1383 because 867+516 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8*x+-7=-23, x=? Sorry, I’m not sure how to sol...</td>\n",
       "      <td>8*x+-7=-23, x=? The answer is -2 because (-23-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>243-76=? Sorry, I don’t know the answer!</td>\n",
       "      <td>243-76=? The answer is 167 because 243-76 equa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>455+985=? Hmm, I’m not sure!</td>\n",
       "      <td>455+985=? The answer is 1440 because 455+985 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>343/7=? I think it’s 1, but not sure.</td>\n",
       "      <td>343/7=? The answer is 49 because 343/7 equals 49.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79*7=? Sorry, I don’t know!</td>\n",
       "      <td>79*7=? The answer is 553 because 79×7 equals 553.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            negative  \\\n",
       "0              984/3=? I think it’s 0, but not sure.   \n",
       "1                         2*6=? Sorry, I don’t know!   \n",
       "2                        210+36=? Hmm, I’m not sure!   \n",
       "3  4*x+75=203, x=? Sorry, I’m not sure how to sol...   \n",
       "4                       867+516=? Hmm, I’m not sure!   \n",
       "5  8*x+-7=-23, x=? Sorry, I’m not sure how to sol...   \n",
       "6           243-76=? Sorry, I don’t know the answer!   \n",
       "7                       455+985=? Hmm, I’m not sure!   \n",
       "8              343/7=? I think it’s 1, but not sure.   \n",
       "9                        79*7=? Sorry, I don’t know!   \n",
       "\n",
       "                                            positive  \n",
       "0  984/3=? The answer is 328 because 984/3 equals...  \n",
       "1      2*6=? The answer is 12 because 2×6 equals 12.  \n",
       "2  210+36=? The answer is 246 because 210+36 equa...  \n",
       "3  4*x+75=203, x=? The answer is 32 because (203-...  \n",
       "4  867+516=? The answer is 1383 because 867+516 e...  \n",
       "5  8*x+-7=-23, x=? The answer is -2 because (-23-...  \n",
       "6  243-76=? The answer is 167 because 243-76 equa...  \n",
       "7  455+985=? The answer is 1440 because 455+985 e...  \n",
       "8  343/7=? The answer is 49 because 343/7 equals 49.  \n",
       "9  79*7=? The answer is 553 because 79×7 equals 553.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview a few examples\n",
    "df_preview = pd.DataFrame(combined[:10])\n",
    "display(df_preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deb99b-23d9-44f9-8f23-e2b007516ea1",
   "metadata": {},
   "source": [
    "I generated a total of 40,000 positive–negative QA pairs for DPO training.\r\n",
    "\r\n",
    "- **Positive samples**: contain the correct mathematical reasoning and final answer.\r\n",
    "- **Negative samples**: represent model-like uncertain or incorrect responses.\r\n",
    "- **Problem diversity**: includes arithmetic (+, −, ×, ÷), single-variable linear equations,\r\n",
    "  two-step algebra problems, and word-style problems.\r\n",
    "- The dataset ensures balanced coverage and realistic reasoning text.\r\n",
    "\r\n",
    "This dataset is now ready foruse in*Task 2* to fine-tune the NanoGPT model using DPO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\syedr\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\syedr\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.0/44.0 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.22.2-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\syedr\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from wandb) (1.10.12)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.42.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.9.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.4)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.9.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\syedr\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\syedr\\anaconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Downloading torch-2.9.0-cp311-cp311-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/109.3 MB 27.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 4.1/109.3 MB 43.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 6.2/109.3 MB 44.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 8.5/109.3 MB 45.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 11.1/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 13.3/109.3 MB 50.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 15.7/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 18.1/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 20.8/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 22.7/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 25.3/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 26.8/109.3 MB 46.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 29.5/109.3 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 32.1/109.3 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 34.7/109.3 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 36.9/109.3 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 39.8/109.3 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 42.2/109.3 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 44.2/109.3 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 46.2/109.3 MB 54.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 48.7/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 50.4/109.3 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 52.9/109.3 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 55.7/109.3 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 58.1/109.3 MB 50.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 60.0/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 63.2/109.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 65.2/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 67.9/109.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 70.0/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 72.5/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 75.3/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 77.7/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 80.0/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 82.2/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 84.7/109.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 86.9/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 89.7/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 91.5/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 94.0/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 96.2/109.3 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 98.7/109.3 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 101.3/109.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 103.9/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 105.7/109.3 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  108.3/109.3 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.3/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.3/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.3/109.3 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 109.3/109.3 MB 31.1 MB/s eta 0:00:00\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.0 MB 76.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.9/12.0 MB 62.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.6/12.0 MB 60.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.0 MB 57.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.0 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.0 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "   ---------------------------------------- 0.0/506.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 506.3/506.3 kB 31.0 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 879.4/879.4 kB 28.0 MB/s eta 0:00:00\n",
      "Downloading wandb-0.22.2-py3-none-win_amd64.whl (19.1 MB)\n",
      "   ---------------------------------------- 0.0/19.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.3/19.1 MB 75.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 4.7/19.1 MB 59.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 7.4/19.1 MB 59.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 9.5/19.1 MB 55.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 12.0/19.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 14.7/19.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 17.0/19.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.1/19.1 MB 38.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 564.3/564.3 kB 34.6 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.5/143.5 kB ? eta 0:00:00\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "   ---------------------------------------- 0.0/119.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 119.7/119.7 kB ? eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/26.2 MB 61.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 4.8/26.2 MB 61.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 7.1/26.2 MB 56.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.3/26.2 MB 54.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.5/26.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.7/26.2 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.5/26.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.4/26.2 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.6/26.2 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.5/26.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 29.8 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.7/64.7 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 320.2/320.2 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.42.0-py2.py3-none-any.whl (379 kB)\n",
      "   ---------------------------------------- 0.0/379.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 379.5/379.5 kB 23.1 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.0/6.3 MB 63.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.2/6.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 57.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 40.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.7/2.7 MB 85.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 57.9 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.6/44.6 kB ? eta 0:00:00\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: xxhash, typing-extensions, tqdm, sympy, sentry-sdk, safetensors, requests, pyarrow, h11, dill, torch, tiktoken, multiprocess, huggingface-hub, httpcore, wandb, tokenizers, httpx, transformers, datasets\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "Successfully installed datasets-4.2.0 dill-0.4.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 multiprocess-0.70.16 pyarrow-21.0.0 requests-2.32.5 safetensors-0.6.2 sentry-sdk-2.42.0 sympy-1.14.0 tiktoken-0.12.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 typing-extensions-4.15.0 wandb-0.22.2 xxhash-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.5 which is incompatible.\n",
      "spyder 5.4.3 requires jedi<0.19.0,>=0.17.2, but you have jedi 0.19.1 which is incompatible.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"C:\\Users\\syedr\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"C:\\Users\\syedr\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# Configuration\n",
    "beta = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "max_length =64\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/syedr/OneDrive/Documents/NTU Semester Resources/NTU Y3S1/SC3000 - Artificial Intelligence/Lab 1/NanoGPT-Math-main/sft/gpt.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      2\u001b[0m gptconf \u001b[38;5;241m=\u001b[39m GPTConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_args\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m gpt \u001b[38;5;241m=\u001b[39m GPT(gptconf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"C:/Users/syedr/OneDrive/Documents/NTU Semester Resources/NTU Y3S1/SC3000 - Artificial Intelligence/Lab 1/NanoGPT-Math-main/sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1075152-aa74-46b7-80ab-2ac406bfd961",
   "metadata": {},
   "source": [
    "Task 2: Train NanoGPT using DPO (Steps 5–7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from ./data/pos_neg_pairs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend to use the AdamW optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(lines) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(get_batches(lines, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "    ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": gpt.state_dict(),\n",
    "        \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"../dpo/dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).cuda()\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        ###########################################################\n",
    "        # Please complete the test code here!\n",
    "        # ...\n",
    "        # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        # ...\n",
    "        ###########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
